---
title: "Forecasting San Diego Power Consumption"
author: "Hunter Blum, Mackenzie Carter, Saba Alemayehu"
date: '2022-11-06'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Libraries
```{r}
library(readxl)
library(rstudioapi)
library(parsedate)
library(lubridate)
library(psych)
library(corrplot)
library(outliers)
library(ggpmisc)
library(gridExtra)

# Note - Tidyverse is a collection of packages, see the Attaching packages section below. Usually best to load last so its functions will mask over other packages.
library(tidyverse)
```

Set Working Directory
```{r}
setwd(dirname(getActiveDocumentContext()$path))
getwd()
```

# Read and Join Data
### San Diego Energy Data
```{r}
SD_energy <- list.files(path = paste0(getwd(), "/EnergyData"),
                        pattern = "*.xlsx",
                        full.names = T) %>% 
  lapply(read_excel) %>% 
  bind_rows()

# They changed the hour variable name between HE and HR, so we'll combine them. CAISO Total was also replaced with CAISO but will be deleted later. Since all NAs are due to name changes it won't be a problem to fill with zero and then sum them to get consistent variable names.

colSums(is.na(SD_energy))
SD_energy <- SD_energy %>% select(!...8)
SD_energy[is.na(SD_energy)] <- 0
SD_energy$HR <- SD_energy$HE + SD_energy$HR


# Get rid of the duplicate variables and non-San Diego company data.
SD_energy <- SD_energy %>% select(-c("HE", "CAISO", "PGE", "SCE", "VEA", "CAISO Total"))
```

### San Diego Weather Data
```{r}
SD_weather <- read.csv("Weather.csv")
```

### Joining
Clean Energy Dates
```{r}
SD_energy <- SD_energy %>% mutate(HR = HR-1)
SD_energy$Date <- ymd_h(paste0(SD_energy$Date, SD_energy$HR))

# Shouldn't need hour variable anymore
SD_energy <- SD_energy %>% select(!HR)
```

Clean Weather Dates
```{r}
# Source 4 takes a measurement every six hours. Source 7 is hourly, so we'll keep Source 7 data.
SD_weather <- SD_weather %>% filter(SOURCE == 7)
SD_weather$DATE <- as_datetime(parse_iso_8601(SD_weather$DATE))  
SD_weather$DATE <- round_date(SD_weather$DATE, unit = "hour")
```

Join
```{r}
SD <- SD_energy %>% left_join(SD_weather, by = c('Date' = 'DATE'))
```

Write
```{r}
write.csv(SD, "SD.csv")
```

# EDA/Cleaning 
Read in data (So you can skip first part)
```{r}
setwd(dirname(getActiveDocumentContext()$path))
SD <- read.csv("SD.csv")
SD <- SD[,-1]
SD <- SD %>% select(Date, SDGE, starts_with("Hourly"))
head(SD)
```

## Structual and General EDA

First, lets take a broad look at our data, including variable types, descriptive statistics and NA counts. 

```{r}
str(SD)
describe(SD)
```

Evaluate missing values by column
```{r}
missing.values <- SD %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) 

missing.values %>%
  ggplot() + 
    geom_bar(aes(x=reorder(key, num.missing), y=num.missing), stat = 'identity') +
    labs(x='Variable', y="Number of missing values", title='Figure X.x: Number of missing values') +
    coord_flip()
```
Evaluate NAs by observation - 304 observations are missing all weather data, we will either need to impute or stick with regression models. 
```{r}
NA_row <- rowSums(is.na(SD))
obs <- seq(1:nrow(SD))

NA_row <- data.frame(obs, NA_row)
NA_row %>% filter(NA_row == 16) %>% tally()
```
Properly format variables
```{r}
# Numeric
SD$HourlyDryBulbTemperature <- as.numeric(as.character(SD$HourlyDryBulbTemperature))
SD$HourlyDewPointTemperature <- as.numeric(as.character(SD$HourlyDewPointTemperature))
SD$HourlyPrecipitation <- as.numeric(as.character(SD$HourlyPrecipitation))
SD$HourlyVisibility <- as.numeric(SD$HourlyVisibility)
SD$HourlyWindDirection <- as.numeric(SD$HourlyWindDirection)

# Factors
SD$HourlyPresentWeatherType <- as.factor(SD$HourlyPresentWeatherType)
SD$HourlySkyConditions <- as.factor(SD$HourlySkyConditions)

# Only run this if you loaded in SD data from EDA
SD$Date <- as_datetime(SD$Date)
```

## Numeric EDA 

```{r}
num <- SD %>% dplyr::select(where(is.numeric))
describe(num)
summary(num)
```

Some columns are almost entirely NA values, for sake of early EDA, we will be dropping these columns for now. 
```{r}
drop <- c("HourlyWindGustSpeed","HourlyPressureTendency", "HourlyPressureChange", "HourlySeaLevelPressure")
num = num[,!(names(num) %in% drop)]
summary(num)
```

Our remaining NA's will be replaced with the median of its column. 
```{r}
num_fill <- num %>% mutate(across(where(is.numeric), ~replace_na(., median(., na.rm=TRUE))))
summary(num_fill)
```

### Outliers 
```{r}
tests = lapply(num_fill, grubbs.test) 
tests
```

The grubbs test shows our max value for wind speed, 33, is an outlier. This makes sense because wind speed ranges in the single digits- it is likely that 33 was a typo. 

Not sure 33 mph winds is a typo, could easily happen in a storm. 

### Correlation
```{r}
M = cor(num_fill)
corrplot(M, addCoef.col = 'black')
```
As we can see from our corrplot, hourly station pressure and hourly altimeter setting are 100% correlated, hourly dry bulb and wet bulb temperature are closely correlated as well, and dew point temp with wet and dry bulb temps. We will be keeping dry bulb temperature as that correlates to ambient temperature. Altimeter setting is another measure of pressure, so we will be keeping hourly station pressure for ease of understanding. 

Correlations below look much better
```{r}
drop2 <- c("HourlyWetBulbTemperature","HourlyAltimeterSetting", "HourlyDewPointTemperature")
num_fill2 = num_fill[,!(names(num_fill) %in% drop2)]
M2 = cor(num_fill2)
corrplot(M2, addCoef.col = 'black')
```

```{r}
ggplot(data = num_fill2, aes(x= HourlyDryBulbTemperature, y=SDGE)) + 
  geom_point() + 
  stat_poly_line() + stat_poly_eq() +
  labs(title="SDGE Usage By Temp", 
         x="Dry Bulb Temp (Â°F)", y = "Hourly Energy Use (MWh)") 
  
```



Scatter plots for numeric features compared to hourly energy use - may need to explore non-linear options and/or how imputation methods affect our numbers. 
```{r}
ScatPlotter.SD <- function(numvar){
  ggplot(num_fill2, aes(x = num_fill2[,numvar], y = SDGE)) +
    geom_point(shape = 1 , alpha = 0.2) +
    stat_poly_line() + stat_poly_eq(geom = "label") +
    xlab(colnames(num_fill2[numvar]))
}

num_cols <- c(2:8)
Scatterplots <- lapply(num_cols, ScatPlotter.SD)
grid.arrange(grobs = Scatterplots, top = "Figure X.x")
```

Time Series for Numeric Features - Moving back to having NAs, since we aren't assessing correlation 
Will make adjustments/sort out features to make graphs easier to read
```{r}
num_withna <- SD %>% select(where(is.numeric))
num_withna$Date <- SD$Date

TS_plotter <- function(x){
  ggplot(num_withna, aes(x = Date)) +
  geom_line(aes(y = num_withna[,x]))+
  ylab(colnames(num_withna[x]))
}

PHP_cols <- c(2,5,6,7,8,9,10)
TWV_cols <- c(3,4,11,12,13,14,15)
TS_target <- TS_plotter(1) + ggtitle("Figure X.x: Time Series for SDGE") 
TS_PHP <- lapply(PHP_cols, TS_plotter)
TS_TWV <- lapply(TWV_cols, TS_plotter)

plot(TS_target) 
grid.arrange(grobs = TS_PHP, top = "Figure X.x: Time Series for Pressure, Humidity, and Precipitation Variables")
grid.arrange(grobs = TS_TWV, top = "Figure X.x: Time Series for Temperature, Wind, and Visibility Variables")
```

Distributions - also will make this look better tomorrow.
```{r}
Hist_plotter <- function(x){
  ggplot(num_withna, aes(x = num_withna[,x])) +
    geom_histogram() +
    xlab(colnames(num_withna[x]))
}

Hist_target <- Hist_plotter(1) + ggtitle("Figure X.x: Distribution for SDGE") 
Hist_PHP <- lapply(PHP_cols, Hist_plotter)
Hist_TWV <- lapply(TWV_cols, Hist_plotter)

plot(Hist_target) 
grid.arrange(grobs = Hist_PHP, top = "Figure X.x: Distribution for Pressure, Humidity, and Precipitation Variables")
grid.arrange(grobs = Hist_TWV, top = "Figure X.x: Distribution for Temperature, Wind, and Visibility Variables")
```

Scatter plots with removed NA instead of imputation: See if it has any effect on linear relationships
```{r}
num_NoNA <- num_withna %>% na.omit()

ScatPlotter.SD <- function(numvar){
  ggplot(num_NoNA, aes(x = num_NoNA[,numvar], y = SDGE)) +
    geom_point(shape = 1 , alpha = 0.2) +
    stat_poly_line() + stat_poly_eq(geom = "label") +
    xlab(colnames(num_NoNA[numvar]))
}

Scat_PHP <- lapply(PHP_cols, ScatPlotter.SD)
Scat_TWV <- lapply(TWV_cols, ScatPlotter.SD)

grid.arrange(grobs = Scat_PHP, top = "Figure X.x: Scatter Plot for Pressure, Humidity, and Precipitation Variables (NAs Removed)")
grid.arrange(grobs = Scat_TWV, top = "Figure X.x: Scatter Plot for Temperature, Wind, and Visibility Variables (NAs Removed)")
```

## Categorical EDA
Bar plots - Not sure this will work with how many categories we have, could maybe use a table or consolidate similar categories.
```{r}
BarPlotter.SD <- function(xvar){
  ggplot(SD, aes_(x = SD[,xvar])) +
    geom_bar(color = "black") + coord_flip() +
    xlab(colnames(SD[xvar]))
}

Barplots <- lapply(c(7,12), BarPlotter.SD)
grid.arrange(grobs = Barplots)
```

Category Count Tables
```{r}
SD %>% group_by(HourlyPresentWeatherType) %>% tally() %>% arrange(desc(n))
SD %>% group_by(HourlySkyConditions) %>% tally() %>% arrange(desc(n))
```

ANOVAs to see if category affects SDGE - Not sure if these are appropriate, may need to look into post-hoc tests since I think having so many categories is forcing significance, will read up on Bonferroni and Tukey tests
```{r}
WT_aov <- aov(SDGE ~ HourlyPresentWeatherType, data = SD)

summary(WT_aov)
```

```{r}
SC_aov <- aov(SDGE ~ HourlySkyConditions, data = SD)

summary(SC_aov)
```